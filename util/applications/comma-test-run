#!/bin/bash

# This file is part of comma, a generic and flexible library
# Copyright (c) 2011 The University of Sydney
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of the University of Sydney nor the
#    names of its contributors may be used to endorse or promote products
#    derived from this software without specific prior written permission.
#
# NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE
# GRANTED BY THIS LICENSE.  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT
# HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED
# WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
# BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
# OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
# IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

name=$( basename $0 )

source $( which comma-application-util ) || { echo "$name: cannot source 'comma-application-util'" >&2; exit 1; }
source $( which comma-random-util ) || { echo "$name: cannot source 'comma-random-util'" >&2; exit 1; }
source $( which comma-units-util ) || { echo "$name: cannot source 'comma-units-util'" >&2; exit 1; }
source $( which comma-resources-util ) || { echo "$name: cannot source 'comma-resources-util'" >&2; exit 1; }
source $( which comma-progress-util ) || { echo "$name: cannot source 'comma-progress-util'" >&2; exit 1; }
source $( which comma-sync-util ) || { echo "$name: cannot source 'comma-sync-util'" >&2; exit 1; }
source $( which comma-env-util ) || { echo "$name: cannot source 'comma-env-util'" >&2; exit 1; }
source $( which comma-string-util ) || { echo "$name: cannot source 'comma-string-util'" >&2; exit 1; }
source $( which comma-process-util ) || { echo "$name: cannot source 'comma-process-util'" >&2; exit 1; }

name_offset="${name//?/ } "
comma_test_run_top_pid=$BASHPID
export name name_offset comma_test_run_top_pid

# determine system parameters and set defaults; command-line options operate in MB
comma_path_value_to_var --prefix=max < <( comma_total_system_resources )
max_resources_memory_main=$(( $max_resources_memory_main / 1024 / 1024 ))
max_resources_memory_shared=$(( $max_resources_memory_shared / 1024 / 1024 ))
data_storage=""
max_parallel=$max_resources_cpus
max_memory_main=$max_resources_memory_main
max_memory_shared=$max_resources_memory_shared
max_wait_time="forever"
max_run_time="3600"

red="\033[0;31m"
green="\033[0;32m"
brown="\033[0;33m"
white="\033[0;37m"
none="\033[m"

function default_options()
{
    cat <<EOF
path=$data_storage
parallel=0
quiet=0
debug=0
until_first_failure=0
max_parallel=$max_parallel
max_memory_main=$max_memory_main
max_memory_shared=$max_memory_shared
max_wait_time=$max_wait_time
max_run_time=$max_run_time
raw=0
EOF
}

function description_test_selection()
{
    cat <<EOF
--black-list=[<file>]; do not run these tests mentioned in <file>, e.g. a lists of sub-directories in white list
  to be excluded; see '--white-list' below for file format.
--end=[<dir>]; run tests up to a given test, the latter excluded, where test directories are ordered lexicographically
--from,--begin=[<dir>]; run tests starting from a given test, where test directories are ordered lexicographically
--run-disabled; run disabled tests
--run-optional,--optional; run tests having file called "optional" (same logic as for --run-disabled)
--stdin; read paths from stdin e.g. run test in hello/world: echo hello/world | comma-test-run --stdin
--to=[<dir>]; run tests up to a given test, the latter included, where test directories are ordered lexicographically
--until-first-failure; exit after the first failure (works only when tests run serially)
--white-list=[<file>]; only run these tests mentioned in the <file>, applied first before black list;
  comment lines starting with # are ignored; each entry in the list matches to a sub-directory or
  directories name using pattern ^<subdir>; see examples
EOF
}

function description_resources()
{
    cat <<EOF
--estimate-resources; in serial mode, accumulates performance data using comma-top into 'output/performance.csv' files;
  note: file may be empty for very short tests
--max-parallel=[<N>]; run up to N tests in parallel; default: $max_parallel
--max-memory-main=[<N>]; limit on main memory, in MB; default: $max_memory_main
--max-memory-shared=[<N>]; limit on shared memory, in MB; default: $max_memory_shared
--max-wait-time=[<time>]; maximal time to wait for available CPUs before failing a test, default: ${max_wait_time}
--max-run-time=[<time>]; maximal time to wait for a test completion before failing it by force, default: ${max_run_time}
--max-resources=[<file>]; specify limits for all resources in path-value format; see config files in verbose help;
  explicit options above have precedence
--parallel; run tests in parallel; default: run serially
EOF
}

function description_others()
{
    cat <<EOF
--also-expected=[<file>]; apply a global expected <file> to the output of tests that have a local 'expected' file;
  pass multiple global files by invoking this option several times
--always-expected,--expected=[<file>]; apply the global expected file to all tests regardless if they have a local
  'expected' file; pass multiple global files by invoking this option several times
--debug; much more debug output
--document,--doc; do not run tests, only output to stdout a collated test documentation in informal way, if --junit present, produce junit-like output (todo)
--junit=[<file>]; output to file junit record compatible with jenkins for each test
--no-ansiterm-control-characters,--no-control-characters,--raw; unstyled output (no ANSIterm control characters)
--output-directories,--dry-run,--dry; output list of test directories intended to run and exit
--path=[<dir>]; data-storage directory for tests, default: none, let the tests define it
--test-option=[<option>]; extra command line argument(s) pass to "test" script

--quiet,-q; minimize output
--verbose,-v; more output
--help,-h; show this help, --help --verbose for more help
EOF
}

function description()
{
    description_test_selection
    description_resources
    description_others
}

function usage_()
{
echo -e "

Search for and execute tests under the current directory.

Find subdirectories containing the files ${brown}test${none}, ${brown}input${none}, or ${brown}expected${none}.
Execute 'test', then either:
    (a) if 'expected' exists, compare its contents to the output of 'test' ("path=value" format)
        'expected' can be either file or directory, see --help --verbose for details
    (b) if --also-expected='file' is passed on the command line and 'expected' exists, compare the contents of
        'file' ("path=value") to the output of 'test'
    (c) if --always-expected='file' is passed on the command line, compare the contents of 'file' ("path=value")
        to the output of 'test'
    (d) otherwise the success of the test depends on the exit status of the 'test' script.

Return 0 if all tests succeed, or non-zero if any of the tests fail.
Output of the test scripts is recorded in ${brown}output/stderr.log${none} and ${brown}output/stdout.log${none}.
A test can have a ${brown}config${none} file to control load balancing, serialisation and maximum run time (see --help --verbose).

Usage: comma-test-run [<options>]

${brown}A quick tutorial${none}

    mkdir success
    echo "hello=\"world\"" > success/input
    echo "hello=\"world\"" > success/expected
    echo "cat" > success/test
    chmod +x success/test

    mkdir failure
    echo "hello=\"world\"" > failure/input
    echo "hello=\"moon\"" > failure/expected
    echo "cat" > failure/test
    chmod +x failure/test

    mkdir config_demo
    echo "resources/serial=\"true\"" > config_demo/config    # run this test serially instead of in parallel
    echo "run/max_time=5" >> config_demo/config              # set the timeout to 5 seconds
    echo "sleep 30" > config_demo/test
    chmod +x config_demo/test

    comma-test-run    # only the "success" test should pass

${brown}Options for test selection${none}
$( description_test_selection | sed 's/^/    /g' )

${brown}Options to control allocated resources${none}
$( description_resources | sed 's/^/    /g' )

${brown}Other options:${none}
$( description_others | sed 's/^/    /g' )

"

[[ -n "$1" ]] || { echo -e "${brown}For more help use: comma-test-run --help --verbose${none}\\n" ; exit 0 ; }

echo -e "

${brown}Input, test, output, and expected files${none}
    File 'input', if exists, is fed to the stdin of the test script.

    If there is an 'input' or 'expected' file but no 'test' in the same directory, the 'test' script in the
    closest parent directory is used. If there is a 'test' by itself with no 'input' or 'expected' file,
    it is only executed if there is no subdirectory containing 'input', 'expected' or 'test'.

    Test output will be put into the subdirectory 'output'. This will contain standard error log 'output/stderr.log'
    and output log 'output/stdout.log'. The contents of 'output/stdout.log' is matched to the 'expected' file.

${brown}expected${none}
    - if 'expected' is a file: compare its contents to the output of 'test' ("path=value" format)
    - if 'expected' is a directory: compare all files in all subdirectories of 'expected', except files called
                                    'readme', to the output of 'test' ("path=value" format)

${brown}Disabling tests${none}
    to disable tests in a directory and all its subdirectories
    create an empty file named ${brown}disabled${none} in that directory

${brown}Optional tests${none}
    you may not want to run some tests by default (e.g. stress tests, very long tests, etc)
    to make tests optional in a directory and all its subdirectories
    create an empty file named ${brown}optional${none} in that directory

${brown}Reading test directories from stdin${none}
    convenient for test filtering and reordering, e.g:
        comma-test-run --dry-run | grep 'some/topic' | comma-test-run --stdin

${brown}Running tests in parallel${none}
    (a) If none of '--parallel' and '--max-parallel' options is given, tests are run sequentially.
    (b) If '--max-parallel' is given, e.g., as in '--max-parallel=4', up to 4 tests are run at once;
        but see below for load-balancing.
    (c) If '--parallel' is given without '--max-parallel', the script attempts to use as many CPUs/cores
        as are available on the system. This is ${red}not recommended${none} for resource-heavy tests
        unless additional configuration files are provided as explained below.

${brown}Config files${none}
    The way a test is run can be controlled using a file named ${brown}config${none} in the test directory,
    which may contain the following parameters:

    resources/cpus=<number>
        Test will not run until the specified number of CPUs are available (out of the '--max-parallel' number).

    resources/memory/shared=<amount> <units>
        Test will not run until the requested amount of shared memory is available (out of the '--max-memory-shared'
        total). Units may be kB, MB, or GB. The amount must be an integer.

    resources/serial=\"true\"
        Test will run only when no other test is running.

    resources/robots/queen=1
    resources/robots/working_bee=10
        Test need one instance of a queen robot and 10 working bee robots (assuming the test knows how to
        use these bots). You must also specify how many instances of such robots are available by passing
        a custom limits file via '--max-resource=limits.pv'; the file 'limits.pv' shall contain limits for
        the robots counters, like:
            resources/robots/queen=1
            resources/robots/working_bee=100

    run/max_time=<seconds>
        Test will be terminated and fail if it has not completed in the specified time (seconds).
        Overrides option '--max-run-time'.

    Example config:
        resources/cpus=4
        resources/memory/shared=3200 MB
        resources/serial=\"true\"
        run/max_time=600

${brown}White(and black)-listing tests${none}
    The test names in the white/black list file shall match ${brown}exactly${none} the corresponding
    names in '--dry-run' output, e.g.
        comma-test-run --dry-run
            ./input/test1
            ./input/test2
            ./output/test1
    then
        echo "./input/test2" > white.list
        comma-test-run --white-list=white.list
    Do not remove leading dots or append input file names or anything similar.

${brown}White(and black)-listing pro hint${none}
    Assume some tests failed:
        comma-test-run > comma-test-run.log 2>&1 ; echo $?
        1
    Create a white list from log file:
        grep run comma-test-run.log | grep failed | sed 's@.*run: @@;s@:.*@@' > white.list
    Fix something and re-run only the failed tests:
        comma-test-run --white-list=white.list
"
    exit 0
}

function error_()
{
    if [[ "$options_no_ansiterm_control_characters" == "1" ]] ; then
        echo -e "$*" >&2
    else
        local bold=$( tput bold )
        local red=$( tput setaf 1 )
        local normal=$( tput sgr0 )
        echo -e "$bold$red$*$normal" >&2
    fi
}
export -f error_

function error_and_junit_()
{
    local -r error_and_junit_formatted=$( echo -e "$1" )
    error_ $( head -1 <<< "$error_and_junit_formatted" )
    local -r error_and_junit_formatted_tail="$( tail -n +2 <<< "$error_and_junit_formatted" )"
    [[ -z "$error_and_junit_formatted_tail" ]] || cat >&2 <<< "$error_and_junit_formatted_tail"
    if [[ -n "$options_junit" && -d 'output' ]] ; then cat >> 'output/junit.failure.log' <<< "$error_and_junit_formatted" ; fi
}
export -f error_and_junit_

function message_()
{
    [[ "$options_quiet" != "1" ]] || return
    if [[ "$options_no_ansiterm_control_characters" == "1" ]] ; then
        echo -e "$1" >&2
    else
        local bold=$( tput bold )
        local normal=$( tput sgr0 )
        echo -e "$bold$1$normal" >&2
    fi
}
export -f message_

function warning_()
{
    [[ "$options_quiet" != "1" ]] || return
    if [[ "$options_no_ansiterm_control_characters" == "1" ]] ; then
        echo -e "$1" >&2
    else
        local bold=$( tput bold )
        local yellow=$( tput setaf 3 )
        local normal=$( tput sgr0 )
        echo -e "$bold$yellow$1$normal" >&2
    fi
}
export -f warning_

function dump_file_()
{
    if [[ "$options_quiet" != "1" ]] ; then cat "$1" >&2 ; fi
}
export -f dump_file_

function disabled_()
{
    local filename=$1   # "disabled" or "optional"
    local dir=$2
    local force=$3
    local verbose=$4
    if [[ "$force" == "1" ]]; then return 1; fi
    if [[ -f "$dir/$filename" ]] ; then
        if [[ "$verbose" == "--verbose" ]]; then
            if [[ -s $dir/$filename ]] ; then warning_ "$name: test $counter: $dir: $filename:" ; cat $dir/$filename | sed 's/^/    /' >&2
            else error_ "$name: test $counter: $dir: $filename (with no explanation)" ; fi
        fi
        return 0
    fi
    local d=$( dirname $dir )
    if [[ "$d" == "$dir" ]] ; then return 1 ; fi
    disabled_ "$filename" "$d" "$force" "$verbose"
    return $?
}
export -f disabled_

# copy input to output, and return failure (1) if there was any output
function fail_on_output()
{
    if grep "."; then return 1; else return 0; fi
}
export -f fail_on_output

# arguments: a list of directories containing "test", "input" and "expected" files
# Outputs the same list, excluding any directories that
# (1) contain only "test" (no "expected" or "input" file), and
# (2) have at least one subdirectory containing another test, OR where "test" itself is a directory
# This is so that it is possible to have a generic "test" script in the base directory that is not
# executed in that directory.
function exclude_generic_tests()
{
    local dir_list=$*
    local result_list=()
    local dir_list_lines=$( echo $dir_list | fmt -1 )

    for dir in $dir_list; do
        if [[ ! -f "$dir/input" && ! -f "$dir/expected" && ! -f "$dir/disabled" ]]; then
            if [[ -d "$dir/test" ]]; then continue; fi
            if [[ -f "$dir/test" ]]; then
                local pattern="^$( comma_escape_special_chars "$dir" )/."
                if grep -q "$pattern" <<<"$dir_list_lines" ; then
                    if [[ "$options_debug" != "0" ]] ; then echo "excluding generic test '$dir/test'" >&2; fi
                    continue
                fi
            fi
        fi
        result_list+=( $dir )
    done

    echo "${result_list[@]}" | tr ' ' '\n'
}

# find "test" file inside a path, checking in each subdirectory (starting from the full path)
# arguments: <path> <file to find>
function closest_file_in_path()
{
    local path="$1"
    local file="$2"
    
    # sanity check (and avoid infinite loop)
    if [[ -z "$path" || -z "$file" ]]; then echo "$name: error: empty path in closest_file_in_path()" >&2; exit 1; fi
    # get canonical name (so path always starts with "/")
    path=$( readlink -e "$path" )

    while true; do
        if [[ -d "$path/$file" ]]; then
            echo "$name: warning: \"$path/$file\" is a directory (expected an executable script); ignoring" >&2
        elif [[ -f "$path/$file" ]]; then
            if [[ $file == "test" && ! -x "$path/$file" ]]; then echo "$name: warning: \"$path/$file\" is not executable; ignoring" >&2 
            else echo $path/$file; break; fi
        elif [[ $path == "/" ]]; then break
        fi
        path=$( dirname "$path" )
    done
}
export -f closest_file_in_path

# "dirname" with multiple arguments allowed (since some versions of "dirname" don't allow them)
function get_dirnames()
{
    local i
    for i in $@; do dirname "$i" ; done
}

function stats_init()
{
    stats="$( pwd )/stats"
    stats_progress_csv="$stats/progress.csv"
    stats_elapsed_path_value="$stats/elapsed.csv"
    rm -rf "$stats" || return 1
    mkdir "$stats" || return 1
    touch "$stats_progress_csv"
    export stats_progress_csv
}

function junit_finalize() # quick and dirty
{
    function junit_testcase()
    {
        local name="$1"
        local log="$2"
        local elapsed="$3"
        [[ -n "$elapsed" ]] || elapsed=0
        local offset
        for i in $( seq $junit_depth ) ; do offset+='    ' ; done
        local attributes="classname=\"testcase\" id=\"$name\" name=\"$name\" time=\"$elapsed\""
        if [[ -s $log ]] ; then
            echo "$offset<testcase $attributes >"
            echo "$offset    <failure>"
            cat $log | recode ascii..html
            echo "$offset    </failure>"
            echo "$offset</testcase>"
        else
            echo "$offset<testcase $attributes />"
        fi
    }
    
    echo "<testsuite tests=\"$( cat $stats_elapsed_path_value | wc -l )\" time=\"$( cat $stats_elapsed_path_value | cut -d= -f2 | csv-calc sum 2>/dev/null )\" >"
    junit_depth=1 # quick and dirty
    cat $stats_elapsed_path_value \
        | while IFS='=' read key elapsed ; do
              local path="$( dirname $key | sed "s#^\./##" )"
              junit_testcase $path $path/output/junit.failure.log $elapsed
              [[ -d "$path/expected" ]] || continue
              local paths=$( ( cd $path/output ; find . -mindepth 2 -name junit.failure.log | sed "s#^\./##" ) )
              echo "    <testsuite tests=\"$( wc -l <<< "$paths" )\" time=\"0\" >"
              junit_depth=2
              for p in $( ( cd $path/output ; find . -mindepth 2 -name junit.failure.log | sed "s#^\./##" ) ) ; do junit_testcase $( dirname $path/$p | sed "s#^\./##" ) $path/output/$p ; done
              junit_depth=1
              echo "    </testsuite>"
          done
    echo "</testsuite>"
}

function stats_finalize()
{
    [[ -f "$stats_progress_csv" ]] || return
    cat "$stats_progress_csv" | comma-progress --elapsed > "$stats_elapsed_path_value"
    [[ -z "$options_junit" ]] || junit_finalize > "$options_junit"
}

function resources_limits()
{
    # the "serial" Boolean is used numerically: false as 0, true as 1, then 1 > 0, etc.
    # the limit of "true" (1) means only 1 task at a time can be serial (occupy this
    # resource to itself)
    [[ -r "$options_max_resources" ]] && cat "$options_max_resources"
    cat <<EOF | name-value-convert --from path-value --to path-value --take-last
resources/cpus=$max_parallel
resources/memory/main=$max_memory_main
resources/memory/shared=$max_memory_shared
resources/serial="true"
EOF
}
export -f resources_limits

# initially no resources are occupied
function comma_test_run_initialize_resources()
{
    comma_test_run_resources_flock="$comma_test_run_unique_dir/resources_flock"
    comma_test_run_resources_counter="$comma_test_run_unique_dir/resources_counter.json"
    comma_test_run_resources_limits="$comma_test_run_unique_dir/resources_limits.json"
    resources_limits | name-value-convert --from path-value --to json > "$comma_test_run_resources_limits"
    touch "$comma_test_run_resources_flock"
    resources_limits | comma_locked "$comma_test_run_resources_flock" comma_initialize_resources "$comma_test_run_resources_counter"
    export comma_test_run_resources_flock comma_test_run_resources_counter comma_test_run_resources_limits
}

# used to initialize variables to non-empty values
function default_requirements()
{
    cat <<EOF
resources/cpus=1
resources/memory/main=0
resources/memory/shared=0
resources/serial="false"
EOF
}
export -f default_requirements

function get_required_resources()
{
    ( 
        default_requirements
        local config=$(closest_file_in_path "." "config")
        [[ -f "$config" ]] && cat "$config"
    ) | comma_path_value_take_last | name-value-convert --from path-value --to json
}
export -f get_required_resources

function report_waiting()
{
    local msg=$1
    [[ "$options_debug" != "0" ]] && {
        [[ "$first" == "true" ]] && {
            echo -n "$name_offset $msg ." >&2
            first="false"
        } || {
            echo -n " ." >&2
        }
    }
}
export -f report_waiting

function report_end_of_wait() {
    [[ "$first" == "false" && "$options_debug" != "0" ]] && echo " end of wait" >&2
    first="true"
}
export -f report_end_of_wait

# auxiliary function to simplify setting the same handler for multiple signals
# _and_ telling the handler which signal has been intercepted
function setup_signal_handler()
{
    local handler=$1
    trap "$handler SIGINT" SIGINT
    trap "$handler SIGTERM" SIGTERM
    trap "$handler SIGHUP" SIGHUP
    trap "$handler SIGPIPE" SIGPIPE
}
export -f setup_signal_handler

function comma_top_wrapper()
{
    trap - SIGINT SIGTERM SIGHUP SIGPIPE  # default handler
    local log=$1
    comma-top --sampling-interval=0.5 > "$log"
}
export -f comma_top_wrapper

function document_test() # todo: handle --document --junit: figure out tag for documentation and trivially implement
{
    function extract_comments() { while read line ; do [[ "$line" =~ ^# ]] || break ; echo $line ; done | sed 's/^#\( \)*//' ; }
    local dir=$1
    (
        cd $dir
        local doc
        if [[ -s "./readme" ]] ; then
            doc=$( cat ./readme )
        else
            if [[ -d "./expected" ]] ; then
                doc="expected directory documentation: todo" # todo: for each file in subdirectories, use extract_comments to output doc
            elif [[ -s "./expected" ]] ; then
                doc+=$( cat ./expected | extract_comments )
            fi
            if [[ -z "$doc" && -s "./input" ]] ; then doc+=$( cat ./input | extract_comments ) ; fi
        fi
        [[ -n "$doc" ]] || { echo "$dir: not documented" ; echo ; return 1 ; }
        echo $dir
        echo "$doc" | sed 's/^/    /'
        echo
    )
}

# this functions executes a provided test with optional input and captures its stdout
# then it optionally compares the output with the expected file
# finally echoes the result of comma-test-match and the status of the match
function run_and_match_test()
{
    local test_failed error_files

    local env_variables="PYTHONPATH,XDG_RUNTIME_DIR,DISPLAY"
    
    rm -rf output || { error_and_junit_ "Unable to remove 'output' directory" ; return 1 ; }
    mkdir -p output || { error_and_junit_ "Unable to make 'output' directory" ; return 1 ; }

    {
        if [[ -f ./input ]] ; then cat ./input ; fi | comma_env --import "$env_variables" "$test_exec" "$path" $verbose $options_test_option
        test_failed=$?
    } >'output/stdout.log' 2>'output/stderr.log'
    error_files="$( find . -name out_of_shared_memory )"
    [[ -n "$error_files" ]] && { error_and_junit_ "'out_of_shared_memory' files found" ; return 1 ; }
    [[ $test_failed == 0 ]] || { error_and_junit_ "Test exited with non-zero status: $test_failed" ; return 1 ; }
    [[ -e 'output' ]] || { error_and_junit_ "'output' directory does not exist" ; return 1 ; }
    [[ -d 'output' ]] || { error_and_junit_ "'output' is not a directory" ; return 1 ; }
    [[ -e 'output/stdout.log' ]] || { error_and_junit_ "'output/stdout.log' file does not exist" ; return 1 ; }
    [[ -f 'output/stdout.log' ]] || { error_and_junit_ "'output/stdout.log' is not a file" ; return 1 ; }
    {
        local match_output global_expected
        echo -e '\n# In comma-test-run before comma-test-match' >> 'output/stdout.log'
        
        function junit_log_error() # quick and dirty; todo: move all junit stuff to one location
        {
            [[ -n "$options_junit" ]] || return
            local dir=$1
            mkdir -p $dir
            touch $dir/junit.failure.log
            [[ -z "$2" ]] || echo "${@:2}" > $dir/junit.failure.log
        }
        
        function match_expected()
        {
            local expected=$1
            local is_global=$2
            if [[ -f "$expected" ]] ; then
                (( options_verbose )) && message_ "$name: match expectations in '$expected'"
                match_output=$( [[ -n "$match_output" ]] && echo "$match_output"; comma-test-match "$expected" <'output/stdout.log' 2>&1 )
            elif [[ -d "$expected" ]] ; then
                local extras=$( find "$expected" -type f )
                for extra in $extras ; do
                    [[ $( basename "$extra" ) != "readme" ]] || continue
                    (( options_verbose )) && message_ "$name: match expectations in '$extra'"
                    local extra_match_output=$( comma-test-match "$extra" < 'output/stdout.log' )
                    [[ $is_global ]] || junit_log_error output/$( sed 's#^\./expected/##' <<< "$extra" ) "$extra_match_output"
                    [[ -z "$extra_match_output" ]] || match_output=$( [[ -n "$match_output" ]] && echo "$match_output"; echo "$extra_match_output" | sed "s#^#$extra:#" 2>&1 )
                done
            fi
        }
        
        match_expected "./expected"
        if [[ -n "$options_also_expected" && -e "./expected" ]] ; then
            for global_expected in $options_also_expected ; do match_expected "$global_expected" "is_global" ; done
        fi
        if [[ -n "$options_always_expected" ]] ; then
            for global_expected in $options_always_expected ; do match_expected "$global_expected" "is_global" ; done
        fi
        echo -e '\n# After comma-test-match in comma-test-run' >> 'output/stdout.log'
        if [[ -n "$match_output" ]]; then
            error_and_junit_ "Test output does not match expected:\nexpected output:\n$match_output"
            return 1
        fi
    }
    return 0
}
export -f run_and_match_test

function get_test_timeout()
{
    local config_timeout
    local config=$(closest_file_in_path "." "config")
    if [[ -f "$config" ]]; then
        config_timeout=$( cat "$config" | name-value-get --from=path-value "run/max_time" )
        if [[ -n $config_timeout ]]; then
            if [[ ! $config_timeout =~ ^[0-9]+$ || $config_timeout -eq 0 ]]; then
                echo "$name: warning: illegal run/max_time '$config_timeout' in $( pwd )/config (expected integer > 0); using default $max_run_time" >&2
                config_timeout=
            fi
        fi
    fi
    echo ${config_timeout:-$max_run_time}
}
export -f get_test_timeout

# helper to terminate comma-top safely
function terminate_comma_top()
{
    comma_process_kill --signal=TERM -$comma_top_pgid "$comma_top_signature"
    local ctrv=$?
    (( $ctrv == 0 )) || error_ "$FUNCNAME: terminating comma-top PID $comma_top_pgid, comma_process_kill returned error '$ctrv'"
    comma-timeout-group --can-wait-for-process-group || { comma_wait_for_process_group "$name" "$comma_top_pgid" 12; wait $comma_top_pgid; }
    unset comma_top_pgid comma_top_signature
}
export -f terminate_comma_top

# this function runs a provided test application under the timeout command
function run_test_with_timeout()
{
    export dir test_exec path
    local timeout_time
    timeout_time=$( get_test_timeout )
    if [[ "$options_estimate_resources" == "1" ]] ; then
        # have to run it manually without comma_execute_and_wait because we are not waiting for it
        # this group of processes would be explicitly terminated when the main test is done
        local our_performance_log="$comma_test_run_unique_dir/performance_log.$( mktemp --dry-run XXXXXXXX )"
        comma_top_pid_fifo="$comma_test_run_unique_dir/pid_fifo.$( mktemp --dry-run XXXXXXXX )"
        mkfifo "$comma_top_pid_fifo" || return 1
        comma_process_exec_and_validate "$comma_top_pid_fifo" comma-timeout-group --wait-for-process-group=22 -s TERM $timeout_time bash -c "comma_top_wrapper \"$our_performance_log\""
        (( $? == 0 )) || { error_ "$FUNCNAME: fatal system error, incorrect \$! reported by bash; re-run your application"; return 1; }
        comma_top_pgid=$!
        comma_top_signature="$comma_process_child_signature"
        rm -f "$comma_top_pid_fifo"
        unset comma_top_pid_fifo
    fi
    comma_execute_and_wait --max-wait=$timeout_time --group "bash -c run_and_match_test"
    local rv=$?
    if [[ "$options_estimate_resources" == "1" ]] ; then
        terminate_comma_top || rv=1
        mv -f "$our_performance_log" "output/performance.csv"
    fi
    return $rv
}
export -f run_test_with_timeout

function terminate_run_single_test()
{
    trap '' SIGINT SIGTERM SIGHUP SIGPIPE
    echo "$name: $FUNCNAME: single test run in $dir terminated by $1..." >&2
    error_and_junit_ "test killed"

    [[ -n "$comma_top_pid_fifo" ]] && rm -f "$comma_top_pid_fifo"
    [[ -n "$comma_top_pgid" ]] && terminate_comma_top

    # serialize all access to global resources: stats file, stdout/err
    (
        flock -x 9
        [[ -f "$our_stderrout_log" ]] && cat "$our_stderrout_log" >&3
        local msg="test $count in '$dir': killed"
        echo "$msg" >&9
    ) 9>>"$comma_test_run_output_flock"

    rm -f "$our_stats_progress"
    (( options_debug )) || rm -f "$our_stderrout_log"

    exit 1
}
export -f terminate_run_single_test

# Auxiliary function to make waiting for resource a one-liner
function random_sleep()
{
    local max_nap=$1
    local sleep_time=$( echo $RANDOM | gawk -v max_nap=$max_nap '{ print $1 * max_nap / 32768 }' )
    wait_time=$( echo $wait_time $sleep_time | gawk '{ print $1 + $2 }' )
    comma_execute_and_wait --group "sleep ${sleep_time}s"
}
export -f random_sleep

# this function runs the actual test; must be run as a background process
# arguments:
#     path to q-storage       - where the data are
#     stats file name         - will write start/stop time into this file
#     verbosity flag          - auxiliary, chatter more/less
#     total                   - total number of tests
#     count                   - sequential test number
#     test directory          - will cd and run the test inside
function run_single_test()
{
    # unquote
    local path=$1 ; local temp="${path%\"}" ; path="${temp#\"}"
    [[ -n "$path" ]] && path="--path=$path"
    local stats_progress=$2 ; temp="${stats_progress%\"}" ; stats_progress="${temp#\"}"
    local verbose=$3 ; temp="${verbose%\"}" ; verbose="${temp#\"}"
    local total=$4
    local count=$5
    local dir=$6 ; temp="${dir%\"}" ; dir="${temp#\"}"
    local worker_id=$BASHPID

    local counter="$count of $total"

    # create a unique file for local comma_progress output; will append to the main output at the end
    our_stats_progress="$comma_test_run_unique_dir/stats_progress.$( mktemp --dry-run XXXXXXXX )"
    # create a unique file for redirecting all output
    # will append to the main output at the end of each test
    local our_stderrout_log="$comma_test_run_unique_dir/stdout_log.$( mktemp --dry-run XXXXXXXX )"

    # prepare to clean up
    local comma_top_pgid comma_top_pid_fifo
    setup_signal_handler terminate_run_single_test

    >"$our_stats_progress"

    # say something so that the user is not guessing what is going on
    (
        flock -x 9
        message_ "$name: test $counter: $dir: started..."
    ) 9>>"$comma_test_run_output_flock"

    # do not touch this equilibristics with file descriptors
    exec 3>&1 4>&2 1>"$our_stderrout_log" 2>&1

    local test_exec basedir outcome
    local result=0
    local request="$comma_test_run_unique_dir/request.${worker_id}.json"

    if disabled_ "disabled" "$dir" "$options_run_disabled" --verbose; then
        :   # message already printed
    elif disabled_ "optional" "$dir" "$options_run_optional" ; then
        warning_ "$name: test $counter: $dir: optional, skipped"
    else
        test_exec=$( closest_file_in_path "$dir" "test" )
        if [[ -z "$test_exec" ]]; then
            error_ "$name: error: no \"test\" script found in any parent directory of $dir"
            result=1
        else
            message_ "$name: test $counter: $dir: running..."

            basedir=$( pwd )

            ## Comment out for now: the exact usage to be discussed, it is confusing and can be taken as a sign of error
            ##[ -f "$dir/readme" ] && dump_file_ "$dir/readme"
            cd "$dir"
            local wait_time=0
            get_required_resources | comma_storage_to_bytes > "$request"
            local first="true"
            local resources_failure_counter=0
            while true ; do
                outcome=$( comma_locked "$comma_test_run_resources_flock" comma_acquire_resources "$request" "$comma_test_run_resources_counter" "$comma_test_run_resources_limits" "$worker_id" )
                if [[ $? == 0 ]] ; then
                    report_end_of_wait
                    local error_files test_failed
                    find . -name out_of_shared_memory | xargs rm -f
                    comma_progress_named "$our_stats_progress" "$dir" run_test_with_timeout
                    test_failed=$?
                    comma_locked "$comma_test_run_resources_flock" comma_release_resources "$request" "$comma_test_run_resources_counter" "$worker_id"
                    (( $? == 0 )) || {
                        error_ "$name: test $counter: $dir: internal error on release_resources, request '$( cat $request )', will try again"
                        comma_locked "$comma_test_run_resources_flock" comma_release_resources "$request" "$comma_test_run_resources_counter" "$worker_id"
                        (( $? == 0 )) || {
                            error_ "$name: test $counter: $dir: repeated internal error on release_resources, terminate the test run PID '$comma_test_run_top_pid'"
                            kill -TERM $comma_test_run_top_pid
                        }
                    }
                    error_files="$( find . -name out_of_shared_memory )"
                    [[ -n "$error_files" ]] && {
                        report_waiting "ran out of shared memory, re-try"
                        echo "$error_files" | xargs rm -f
                        continue
                    }
                    [[ "$test_failed" == "0" ]] && {
                        message_ "$name: test $counter: $dir: succeeded"
                    } || {
                        result=1
                        error_ "$name: $dir: failed$( (( $test_failed == 124 )) && echo ' (likely timed out)' )"
                        [[ -n "$options_junit" && $test_failed == 124 ]] && echo "likely timed out" >> "output/junit.failure.log"
                    }
                    break
                else
                    if [[ "$outcome" == wait* ]] ; then
                        report_waiting "waiting for resources"
                        [[ "$max_wait_time" != "forever" ]] && {
                            if gawk '{ a=$1 > $2; exit !a }' < <( echo $wait_time $max_wait_time ) ; then
                                echo "$name: in '$dir', could not get requested resources for ${wait_time}s, failed to run" >&2
                                result=1
                                break
                            fi
                        }
                        local position=$( echo "$outcome" | cut -d, -f2 )
                        position=${position:-"0"}
                        local positional_delay=1  # make a configuration parameter
                        random_sleep $( echo "1 + $positional_delay * $position" | bc )
                        continue
                    else
                        error_ "$name: test $counter: $dir: internal error on acquire_resources, outcome '$outcome', request '$( cat $request )'"
                        # this is a rare internal error; we can be already on the queue, and have to deal with it
                        if (( ++resources_failure_counter < 2 )) ; then
                            error_ "$name: test $counter: $dir: first time, will try again"
                            sleep 1  # do not count as waiting time, for simplicity
                            continue
                        else
                            error_ "$name: terminate the test run with PID '$comma_test_run_top_pid'"
                            kill -TERM $comma_test_run_top_pid
                        fi
                    fi
                fi
            done
            [[ -n "$options_junit" && $result != 0 && ! -f "output/junit.failure.log" ]] && echo "internal error, see detailed log" >> "output/junit.failure.log"
            cd "$basedir"
        fi
    fi

    # serialize all access to global resources: stats file, stdout/err
    (
        flock -x 9
        cat "$our_stats_progress" >> "$stats_progress"
        cat "$our_stderrout_log" >&3
        local msg="test $count in '$dir': "
        (( $result == 0 )) && { msg+="success"; } || { msg+="failed"; }
        echo "$msg" >&9
    ) 9>>"$comma_test_run_output_flock"

    rm -f "$our_stats_progress"
    (( options_debug )) || rm -f "$our_stderrout_log"

    return $result
}
export -f run_single_test

function terminate_tests_parallel()
{
    trap '' SIGINT SIGTERM SIGHUP SIGPIPE
    echo "$name: parallel test run terminated by $1..." >&2
    rm -f "$comma_test_run_xargs_pipe"
    is_killed=true
    # a process that exits in response to SIGINT should kill itself with SIGINT
    # see http://www.cons.org/cracauer/sigint.html
    [[ "$1" == "SIGINT" ]] && { trap - INT ; kill -INT $BASHPID ; }
    exit 1
}

function tests_parallel_xargs_reader()
{
    xargs -P $max_parallel -I{} bash -c run_single_test\ "'$options_path'"\ "'$stats_progress_csv'"\ "'$verbose'"\ "'$test_scripts_count'"\ {} < "$1"
}
export -f tests_parallel_xargs_reader

function process_tests_parallel()
{
    setup_signal_handler terminate_tests_parallel
    comma_test_run_xargs_pipe="$comma_test_run_unique_dir/xargs.pipe"
    mkfifo -m 600 "$comma_test_run_xargs_pipe" || return 1
    # do not care about wrapping this pipeline into comma_execute_and_wait: once the reader (below) is gone and pipe is removed, this pipeline will die by itself
    local tests_parallel_xargs_writer_pid
    cat | xargs -n2 >"$comma_test_run_xargs_pipe" & tests_parallel_xargs_writer_pid=$!
    comma_execute_and_wait --group "bash -c tests_parallel_xargs_reader \"$comma_test_run_xargs_pipe\"" #"bash -c tests_parallel_xargs_writer \"$comma_test_run_xargs_pipe\""
    (( $? != 0 )) && result=1
    wait $tests_parallel_xargs_writer_pid
    unset tests_parallel_xargs_writer_pid
    rm -f "$comma_test_run_xargs_pipe"
    unset comma_test_run_xargs_pipe
}

function terminate_tests_serial()
{
    trap '' SIGINT SIGTERM SIGHUP SIGPIPE
    echo "$name: serial test run terminated by $1..." >&2
    is_killed=true
    # a process that exits in response to SIGINT should kill itself with SIGINT
    # see http://www.cons.org/cracauer/sigint.html
    [[ "$1" == "SIGINT" ]] && { trap - INT ; kill -INT $BASHPID ; }
    exit 1
}

function process_tests_serial()
{
    setup_signal_handler terminate_tests_serial
    local dir counter rv
    while true; do
        read counter dir
        [[ -z "$dir" ]] && break
        # note: dir variable is already quoted
        comma_execute_and_wait --process "bash -c run_single_test \"$options_path\" \"$stats_progress_csv\" \"$verbose\" $test_scripts_count $counter $dir"
        rv=$?
        (( $rv == 0 )) || {
            result=1
            [[ "$options_until_first_failure" == "1" ]] && return 1
        }
    done
    return 0
}

function count_failures()
{
    (
        flock -x 9
        grep -c "\<failed\>" "$comma_test_run_output_flock"
    ) 9>>"$comma_test_run_output_flock"
}
export -f count_failures

function clean_working_dir() { [[ "$options_debug" == "0" && -n "$comma_test_run_unique_dir" ]] && rm -fr "$comma_test_run_unique_dir" ; }

function final_words()
{
    local failed_count=$( count_failures )
    local afterword=
    [[ "$is_killed" == "true" ]] && afterword=" (before killed)"
    if [[ "$failed_count" == 0 ]] ; then message_ "$name: $test_scripts_count test[s] in subdirectories of $( pwd ): succeeded${afterword}" ; else error_ "$name: $test_scripts_count test[s] in subdirectories of $( pwd ): $failed_count test[s] out of $test_scripts_count failed${afterword}" ; fi
    [[ "$options_debug" != "0" && -n "$comma_test_run_output_flock" ]] && { echo "$name: detailed breakdown:" >&2 ; cat "$comma_test_run_output_flock" >&2; }
}

function cleanup()
{
    trap '' SIGHUP SIGINT SIGTERM SIGPIPE   # ignore signals
    stats_finalize
    final_words
    clean_working_dir
}

function parse_multiple_options()
{
    local option=$1
    shift
    [[ -n "$option" ]] || return 1
    local filename
    # filename is always quoted by comma-options-to-name-value; remove first and last characters with sed
    for filename in $( description | comma-options-to-name-value $@ | grep "$option" | cut -d= -f2 | sed 's@^.@@;s@.$@@' ) ; do
        [[ -r $filename ]] || { error_ "$name: cannot find $filename given as argument of '$option'"; return 1 ; }
        readlink -e "$filename"
    done
}

# process command line...
(( $( comma_options_has --bash-completion $@ ) )) && { description | comma_options_to_bash_completion ; exit 0 ; }
(( $( comma_options_has --description $@ ) )) && { description ; exit 0 ; }
if (( $( comma_options_has --help $@ ) || $( comma_options_has -h $@ ) )) ; then
    (( $( comma_options_has --verbose $@ ) || $( comma_options_has -v $@ ) )) && usage_ --verbose || usage_
fi

description | comma-options-validate $@
comma_path_value_to_var --export --prefix=options < <( default_options )
options_path_value="$( description | comma-options-to-name-value $@ )"
comma_path_value_to_var --export --prefix=options <<<"$options_path_value"

options_test_option=$( echo "$options_path_value" |  grep "^test-option=" | cut -d'=' -f2- | sed 's#^"##;s#"$##' | tr '\n' ' ' )

# and perform sanity check
[[ -n "$options_path" && ! -d "$options_path" ]] && { error_ "$name: directory '$options_path' not found"; exit 1; }
have_max_parallel_equal=$( comma_options_has --max-parallel=$options_max_parallel $@ )
have_max_parallel_space=$( comma_options_has --max-parallel $@ )
have_max_parallel=$(( have_max_parallel_equal > 0 || have_max_parallel_space > 0 ))
(( $options_parallel == 0 && $have_max_parallel == 0 )) && options_max_parallel=1
(( $have_max_parallel != 0 )) && options_parallel=1
(( $options_max_parallel < 1 )) && { error_ "$name: number of parallel tests $options_max_parallel < 1"; exit 1; }
(( $options_max_memory_main < 1 )) && { error_ "$name: amount of shared memory $options_max_memory_main < 1 MB"; exit 1; }
(( $options_max_memory_shared < 1 )) && { error_ "$name: amount of shared memory $options_max_memory_shared < 1 MB"; exit 1; }
[[ "$options_max_wait_time" != "forever" ]] && {
    (( $options_max_wait_time < 1 )) && { error_ "$name: wait time $options_max_wait_time < 1s or not a number"; exit 1; }
}
(( $options_max_run_time < 1 )) && { error_ "$name: timeout run time $options_max_run_time < 1s or not a number"; exit 1; }
[[ "$options_parallel" != "0" && "$options_estimate_resources" == "1" ]] && { error_ "$name: resource estimation shall be serial"; exit 1; }
if [[ "$options_debug" != "0" ]] ; then verbose="--verbose" ; fi
(( options_verbose )) && verbose="--verbose"
if [[ -n "$options_junit" ]] ; then
    type -p recode >/dev/null || { error_ "$name: --junit given, but recode is not found; please install recode; e.g. run: sudo apt-get install recode"; exit 1; }
    rm -f "$options_junit"
fi
[[ -n "$options_also_expected" ]] && {
    [[ -f "$options_also_expected" ]] || { error_ "$name: global expected file '$options_also_expected' not found"; exit 1; }
    options_also_expected=$( readlink -e "$options_also_expected" )
}

# handle separately the options that can be repeated multiple times
# have to store all names in one string because arrays cannot be exported
# as a consequence, may not have spaces in file names
options_always_expected=$( parse_multiple_options "always-expected" $@ ) || exit 1
options_also_expected=$( parse_multiple_options "also-expected" $@ ) || exit 1

# and convert to bytes and export for everyone to use
max_parallel=$options_max_parallel
max_memory_main=$(( $options_max_memory_main * 1024 * 1024 ))
max_memory_shared=$(( $options_max_memory_shared * 1024 * 1024 ))
max_wait_time=$options_max_wait_time
max_run_time=$options_max_run_time
# all "options_*" variables have been already exported
export max_parallel max_memory_main max_memory_shared max_wait_time max_run_time verbose

function apply_white_list() { if [[ -n "$options_white_list" ]] ; then grep -E "$options_white_list"; else cat ; fi ; }

function apply_black_list() { if [[ -n "$options_black_list" ]] ; then grep -vE "$options_black_list"; else cat ; fi ; }

function apply_white_black_list() { apply_white_list | apply_black_list ; }

# to run, search for directories containing either "test", "input" or "expected";
# if "test" is absent, use the "test" in the closest parent directory
function test_directories()
{
    if [[ -n "$options_white_list" && -f "$options_white_list" ]]; then
        message_ "$name: applying white list from file '$options_white_list'"
        options_white_list="^(\./)?($( sed 's#\./##' <$options_white_list | grep -v ^# | grep -v ^$ | tr \\n '|' | sed 's/|$//'  ))";
    fi
    if [[ -n "$options_black_list" && -f "$options_black_list" ]]; then
        message_ "$name: applying black list from file '$options_black_list'"
        options_black_list="^(\./)?($( sed 's#\./##' <$options_black_list | grep -v ^# | grep -v ^$ | tr \\n '|' | sed 's/|$//' ))";
    fi

    test_script_dirs_all=( $( exclude_generic_tests $( get_dirnames $( find . -name "test" -or -name "input" -or -name "expected" | grep -v "/\." ) 2>/dev/null | sort -u ) | apply_white_black_list ) )
    [[ -n "$options_from" || -n "$options_to" || -n "$options_end" ]] || { echo ${test_script_dirs_all[@]} ; return ; }
    [[ -z "$options_from" ]] || { local from="${options_from#\.\/}" ; }
    [[ -z "$options_to" ]] || { local to="${options_to#\.\/}" ; }
    [[ -z "$options_end" ]] || { local end="${options_end#\.\/}" ; }
    for d in ${test_script_dirs_all[@]} ; do
        local e="${d#\.\/}"
        [[ -z "$from" || "$e" == "$from" ]] || continue
        unset from
        [[ -z "$end" || "$e" != "$end" ]] || return
        echo $d
        [[ -z "$to" || "$e" != "$to" ]] || return
    done
}

if [[ -z "$options_stdin" ]] ; then
    test_script_dirs=( $( test_directories ) )
else
    while read line ; do
        [[ -d "$line" ]] || { echo "$name: directory not found: \"$line\"" >&2 ; exit 1 ; }
        test_script_dirs+=( "$line" )
    done
fi
[[ -z "$options_output_directories" ]] || { echo ${test_script_dirs[@]} | tr ' ' '\n' ; exit 0 ; }
[[ -z "$options_document" ]] || { for d in ${test_script_dirs[@]} ; do document_test $d ; done ; exit 0 ; }
export test_scripts_count=${#test_script_dirs[@]}

export comma_test_run_unique_dir=
export comma_test_run_output_flock=
trap cleanup EXIT
stats_init || { error_ "$name: could not initialize stats"; exit 1; }

# keep all plumbing under a common directory
temp_dir=$( readlink -e "stats" )
comma_test_run_unique_dir=$( mktemp --directory --tmpdir="$temp_dir" comma-test-run.XXXXXXXX ) || { error_ "$name: cannot create unique working directory"; exit 1; }
export comma_test_run_unique_dir
# to run tests in parallel, we need to lock stats_progress_csv and/or stdout/stderr
# this is the global flock name
comma_test_run_output_flock="$comma_test_run_unique_dir/output_flock"
export comma_test_run_output_flock

# store the currently occupied resources (number of CPUs, amount of memory)
# in a global file name; access serialized via flocks
comma_test_run_initialize_resources

result=0
run_tests="process_tests_parallel"
[[ "$options_parallel" == "0" ]] && run_tests="process_tests_serial"

function generate_test_directories()
{
    local dir
    for dir in "${test_script_dirs[@]}" ; do
        (( ++count ))
        echo "$count  \"$dir\""
    done
}

count=0
if (( $test_scripts_count > 0 )) ; then
    message_ "$name: $test_scripts_count test[s] in subdirectories of $( pwd ): running..."
    $run_tests < <( generate_test_directories )
else
    echo -e "${brown}$name: warning: no tests found in $( pwd )${none}" >&2
fi

exit $result
